{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 2080 Ti\n",
      "Found local copy...\n",
      "Found local copy...\n",
      "Found local copy...\n",
      "Found saved processed KG... Loading...\n",
      "Splits detected... Loading splits....\n",
      "Creating DGL graph....\n",
      "additional \n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from txgnn import TxGNN, TxEval, TxData, NewDataHandler\n",
    "from txgnn.utils import *\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "split = \"complex_disease\"\n",
    "seed = 1\n",
    "saving_path = './properly_pre_trained_model_ckpt/'\n",
    "\n",
    "TxData1 = TxData(data_folder_path = './data/')\n",
    "# psuedo_label_fname = \"psuedo_scores_in_og_dataset.csv\"\n",
    "# pseudo_labels = pd.read_csv(psuedo_label_fname)\n",
    "# TxData1.prepare_split(split = split, seed = seed, no_kg = False, additional_train=pseudo_labels, soft_pseudo=True)\n",
    "TxData1.prepare_split(split = split, seed = seed, no_kg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TxGNN1 = TxGNN(\n",
    "        data = TxData1, \n",
    "        weight_bias_track = False,\n",
    "        proj_name = 'TxGNN',\n",
    "        exp_name = 'TxGNN'\n",
    "    )\n",
    "TxGNN1.model_initialize(n_hid = 100, \n",
    "                        n_inp = 100, \n",
    "                        n_out = 100, \n",
    "                        proto = True,\n",
    "                        proto_num = 3,\n",
    "                        attention = False,\n",
    "                        sim_measure = 'all_nodes_profile',\n",
    "                        bert_measure = 'disease_name',\n",
    "                        agg_measure = 'rarity',\n",
    "                        num_walks = 200,\n",
    "                        walk_mode = 'bit',\n",
    "                        path_length = 2,\n",
    "                        LSP_size=\"partial\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from path: ./properly_pre_trained_model_ckpt/seed_1_restrained_saveG/\n",
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "Accuracy for Positive train graph is 0.91464763879776\n",
      "Accuracy for Negative train graph is 0.847159743309021\n",
      "Accuracy for Positive val graph is 0.5796563029289246\n",
      "Accuracy for Negative val graph is 0.8091035485267639\n",
      "Accuracy for Positive test graph is 0.7104736566543579\n",
      "Accuracy for Negative test graph is 0.8085390329360962\n",
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "Validation Loss 0.6954,  Validation Micro AUROC 0.7884 Validation Micro AUPRC 0.7956 Validation Macro AUROC 0.8100 Validation Macro AUPRC 0.8125\n",
      "----- AUROC Performance in Each Relation -----\n",
      "('drug', 'contraindication', 'disease'): 0.7654884075564711\n",
      "('drug', 'indication', 'disease'): 0.8545225150784468\n",
      "----- AUPRC Performance in Each Relation -----\n",
      "('drug', 'contraindication', 'disease'): 0.7757623336739281\n",
      "('drug', 'indication', 'disease'): 0.8492547770313157\n",
      "----------------------------------------------\n",
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "Testing Loss 0.5073 Testing Micro AUROC 0.8494 Testing Micro AUPRC 0.8209 Testing Macro AUROC 0.8582 Testing Macro AUPRC 0.8273\n",
      "----- AUROC Performance in Each Relation -----\n",
      "('drug', 'contraindication', 'disease'): 0.8322355742234001\n",
      "('drug', 'indication', 'disease'): 0.8840800259719179\n",
      "----- AUPRC Performance in Each Relation -----\n",
      "('drug', 'contraindication', 'disease'): 0.7869879902265018\n",
      "('drug', 'indication', 'disease'): 0.8675448004135727\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--save_dir', type=str, help=\"fname in properly_pre_trained_model_ckpt folder\") #### Test #### How about without default=None, is this implied? \n",
    "# args = parser.parse_args()\n",
    "# save_dir = f'{saving_path}seed_1_restrained_saveG'\n",
    "\n",
    "# TxGNN1.pretrain(n_epoch = 1, ## was 2\n",
    "#                learning_rate = 1e-3,\n",
    "#                batch_size = 1024, \n",
    "#                train_print_per_n = 20)\n",
    "\n",
    "# TxGNN1.finetune(n_epoch = 500, #---\n",
    "#                 learning_rate = 5e-4,\n",
    "#                 train_print_per_n = 5,\n",
    "#                 valid_per_n = 20,)\n",
    "\n",
    "# save_dir = f'{saving_path}seed_1_restrained'\n",
    "# TxGNN1.load_pretrained(save_dir, legacy=True)\n",
    "\n",
    "save_dir = f'{saving_path}seed_1_restrained_saveG/'\n",
    "TxGNN1.load_pretrained(save_dir)\n",
    "\n",
    "G = TxGNN1.G.to(TxGNN1.device)\n",
    "best_G = TxGNN1.best_G.to(TxGNN1.device)\n",
    "best_model = TxGNN1.best_model.to(TxGNN1.device)\n",
    "best_model.eval()\n",
    "# print(TxGNN1.dd_etypes.device)\n",
    "# TxGNN1.model = TxGNN1.model.to(TxGNN1.device)\n",
    "# TxGNN1.best_model = TxGNN1.best_model.to(TxGNN1.device)\n",
    "# print(TxGNN1.model)\n",
    "# print(\"encore\")\n",
    "\n",
    "## Print out accuracies\n",
    "neg_sampler = Full_Graph_NegSampler(TxGNN1.G, 1, 'fix_dst', TxGNN1.device)\n",
    "g_train_neg = neg_sampler(TxGNN1.G)\n",
    "g_valid_pos, g_valid_neg = TxGNN1.g_valid_pos, TxGNN1.g_valid_neg\n",
    "g_test_pos, g_test_neg = TxGNN1.g_test_pos, TxGNN1.g_test_neg\n",
    "## parameters: (model, G, train_pos, train_neg, val_pos, val_neg, test_pos, test_neg, device=None)\n",
    "accuracies_dict = evaluate_accuracy_per_split(best_model, best_G, g_train_neg, g_valid_pos, g_valid_neg, g_test_pos, g_test_neg)\n",
    "for k, v in accuracies_dict.items():\n",
    "    print(f\"Accuracy for Positive {k} graph is {v[0].item()}\")\n",
    "    print(f\"Accuracy for Negative {k} graph is {v[1].item()}\")\n",
    "print_val_test_auprc(best_model, g_valid_pos, g_valid_neg, g_test_pos, g_test_neg, best_G, TxGNN1.dd_etypes, TxGNN1.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9388, device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TxGNN1.g_pos_pseudo\n",
    "best_G\n",
    "# torch.where(best_G.edges(etype=('drug', 'indication', 'disease')))\n",
    "# torch.where(best_G.in_degrees(etype=('drug', 'indication', 'disease')))\n",
    "sum(best_G.in_degrees(etype=('drug', 'indication', 'disease')))\n",
    "sum(TxGNN1.g_pos_pseudo.in_degrees(etype=('drug', 'indication', 'disease')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = TxGNN1.df_train\n",
    "# df_train[y_id]\n",
    "disease_keyid = torch.where(best_G.in_degrees(etype=('drug', 'indication', 'disease')))[0]\n",
    "# disease_queryid = torch.where(TxGNN1.g_pos_pseudo.in_degrees(etype=('drug', 'indication', 'disease')))[0]\n",
    "disease_queryid = torch.tensor([39], device=torch.device(\"cuda\"))\n",
    "\n",
    "mask = torch.isin(disease_queryid, disease_keyid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12661, 12661, 12661,  ...,  4301, 15175, 13194], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TxGNN1.g_valid_pos.edges(etype=('drug', 'indication', 'disease'))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3885/1518374656.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"len() of a 0-d tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             warnings.warn(\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of a 0-d tensor"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why are we seeing so many Falses when training with pseudo labels?\n",
    "    ## Because not all diseases with specific edge type in eval graph is in Train Graph\n",
    "    ## This suggests maybe it is beneficial for \"complex diseases\" to not use any DPM during training? \n",
    "\n",
    "## Let's make sure that according to the theory above, we should see True rate of 80% during training with  pseudo labels\n",
    "    ## How come the above is like nan or 501 when I'm training with pseudo labels? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using stored similarity matrix for ('disease', 'disease_disease', 'disease')\n",
      "Using stored similarity matrix for ('gene/protein', 'disease_protein', 'disease')\n",
      "time it took to create the sparse tensor: 1.7757363319396973\n"
     ]
    }
   ],
   "source": [
    "# kg_path = os.path.join('./data', 'kg_directed.csv')\n",
    "# full_kg_df = pd.read_csv(kg_path)\n",
    "# train_kg = create_dgl_graph(best_G, best_G).to(TxGNN1.device)\n",
    "# full_kg = create_dgl_graph(full_kg_d\"f, best_G).to(TxGNN1.device)\n",
    "\n",
    "h, beta_kl_loss, distmult = best_model(best_G, pretrain_mode = False, mode = 'train', return_h_and_kl=True)\n",
    "# pos_score, out_pos, LS = distmult(best_G, best_G, h, mode=None, pretrain_mode=False, LSP=\"L2\")\n",
    "_, _, LS = distmult(best_G, best_G, h, mode=None, pretrain_mode=False, LSP=\"RBF\", LSP_size=\"partial\")\n",
    "# pred_score_pos, out_pos = distmult(g_valid_pos, best_G, h, mode=None, pretrain_mode=False)\n",
    "# _, _, LS = distmult(self.g_pos_pseudo, self.G, h, mode=None, pretrain_mode=False, pseudo_training=True, LSP=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17080"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(LS._nnz())\n",
    "# print(LS.coalesce()._nnz())\n",
    "LS_prob = []\n",
    "for i, v in enumerate(LS):\n",
    "    softmaxed = F.softmax(v)\n",
    "    LS_prob.append(softmaxed)\n",
    "len(LS_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch.save(LS_prob, \"LSP_full_RBF.pt\")\n",
    "torch.save(LS_prob, \"LSP_partial_RBF.pt\")\n",
    "\n",
    "# LS\n",
    "# LS_target =  torch.load(\"LSP_partial_cosine.pt\")\n",
    "# LS_target =  LS_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSP_loss = 0\n",
    "# for i, (LS_i, LS_target_i) in enumerate(zip(LS, LS_target)):\n",
    "#     LS_i = LS_i.coalesce()\n",
    "#     LS_target_i = LS_target_i.coalesce()\n",
    "#     if len(LS_i.values()) > 0:\n",
    "#         ## softmax LS_i\n",
    "#         try:\n",
    "#             pred_prob = F.softmax(LS_i.values())\n",
    "#             # target_prob = F.softmax(LS_target_i.values())\n",
    "#             target_prob = LS_target_i.values()\n",
    "#             ## compute loss\n",
    "#             LSP_loss = LSP_loss + F.kl_div(pred_prob.log(), target_prob)\n",
    "#         except Exception as e:\n",
    "#             print(i)\n",
    "#             print(e)\n",
    "#             # print(LS_i.indices())\n",
    "#             # print(LS_target_i.indices())\n",
    "            \n",
    "#             # print(LS_i.values())    \n",
    "#             # print(LS_target_i.values())\n",
    "#     #         print(pred_prob.shape, target_prob.shape)\n",
    "# LSP_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([0.0453, 0.0405, 0.0441, 0.0418, 0.0441, 0.0430, 0.0311, 0.0397, 0.0419,\n",
      "        0.0258, 0.0453, 0.0407, 0.0453, 0.0451, 0.0404, 0.0441, 0.0282, 0.0442,\n",
      "        0.0390, 0.0455, 0.0451, 0.0441, 0.0447, 0.0239, 0.0272],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# for i, (LS_i, v2) in enumerate(zip(LS_, temp)):\n",
    "#     LS_i = LS_i.coalesce()\n",
    "#     print(i)\n",
    "#     pred = LS_i.values()\n",
    "#     pred_prob = F.softmax(pred)\n",
    "#     print(pred_prob)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,     0,     0,  ..., 17077, 17079, 17079], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# for i,v in enumerate(LS_):\n",
    "#     print(i)\n",
    "#     print(v)\n",
    "#     break\n",
    "\n",
    "# for i,v in enumerate(LS_.indices()):\n",
    "#     print(i)\n",
    "#     print(v)\n",
    "#     break\n",
    "\n",
    "# for v in LS_.indices():\n",
    "#     print(v)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (LS_.coalesce().indices() == LS_.coalesce().indices()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0453, 0.0405, 0.0441,  ..., 0.0111, 0.0115, 0.0123], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# indices = LS_.indices()\n",
    "# norm_values = []\n",
    "# for i in range(17080):\n",
    "#     mask = indices[0] == i\n",
    "#     compressed_tensor = LS_.values()[mask]\n",
    "#     norm_ct = F.softmax(compressed_tensor)\n",
    "#     norm_values.append(norm_ct)\n",
    "    \n",
    "# norm_values = torch.cat(norm_values)\n",
    "# print(norm_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0453, 0.0405, 0.0441, 0.0418, 0.0441, 0.0430, 0.0311, 0.0397, 0.0419,\n",
      "        0.0258, 0.0453, 0.0407, 0.0453, 0.0451, 0.0404, 0.0441, 0.0282, 0.0442,\n",
      "        0.0390, 0.0455, 0.0451, 0.0441, 0.0447, 0.0239, 0.0272],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    mask = indices[0] == i\n",
    "    print(norm_values[mask])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3115, 0.4254, 0.6658, 0.4438, 0.4059, 0.1487, 0.1337, 0.1096],\n",
       "       device='cuda:0', grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask = LS_.indices()[0] == 333\n",
    "# LS_target.values()[mask]\n",
    "# LS_.values()[mask]\n",
    "# LS_.values().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 17079, 17079, 17079],\n",
       "                       [   67,   188,  6340,  ..., 47585, 89183, 93538]]),\n",
       "       values=tensor([0.0453, 0.0405, 0.0441,  ..., 0.0111, 0.0115, 0.0123]),\n",
       "       device='cuda:0', size=(17080, 100001), nnz=284544,\n",
       "       layout=torch.sparse_coo,\n",
       "       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LS_prob = torch.sparse_coo_tensor(indices, norm_values, LS_.size())\n",
    "LS_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(LS_.coalesce().indices() == LS_prob.coalesce().indices()).float().mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[  0,   1,   2,  ..., 517, 518, 519],\n",
       "                       [ 20,  21,  22,  ..., 497, 498, 499]]),\n",
       "       values=tensor([ 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007,\n",
       "                      1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016,\n",
       "                      1017, 1018,  999, 1019, 1000, 1020, 1001, 1021, 1002,\n",
       "                      1022, 1003, 1023, 1004, 1024, 1005, 1025, 1006, 1026,\n",
       "                      1007, 1027, 1008, 1028, 1009, 1029, 1010, 1030, 1011,\n",
       "                      1031, 1012, 1032, 1013, 1033, 1014, 1034, 1015, 1035,\n",
       "                      1016, 1036, 1017, 1037, 1018, 1038, 1019, 1039, 1020,\n",
       "                      1040, 1021, 1041, 1022, 1042, 1023, 1043, 1024, 1044,\n",
       "                      1025, 1045, 1026, 1046, 1027, 1047, 1028, 1048, 1029,\n",
       "                      1049, 1030, 1050, 1031, 1051, 1032, 1052, 1033, 1053,\n",
       "                      1034, 1054, 1035, 1055, 1036, 1056, 1037, 1057, 1038,\n",
       "                      1058, 1039, 1059, 1040, 1060, 1041, 1061, 1042, 1062,\n",
       "                      1043, 1063, 1044, 1064, 1045, 1065, 1046, 1066, 1047,\n",
       "                      1067, 1048, 1068, 1049, 1069, 1050, 1070, 1051, 1071,\n",
       "                      1052, 1072, 1053, 1073, 1054, 1074, 1055, 1075, 1056,\n",
       "                      1076, 1057, 1077, 1058, 1078, 1059, 1079, 1060, 1080,\n",
       "                      1061, 1081, 1062, 1082, 1063, 1083, 1064, 1084, 1065,\n",
       "                      1085, 1066, 1086, 1067, 1087, 1068, 1088, 1069, 1089,\n",
       "                      1070, 1090, 1071, 1091, 1072, 1092, 1073, 1093, 1074,\n",
       "                      1094, 1075, 1095, 1076, 1096, 1077, 1097, 1078, 1098,\n",
       "                      1079, 1099, 1080, 1100, 1081, 1101, 1082, 1102, 1083,\n",
       "                      1103, 1084, 1104, 1085, 1105, 1086, 1106, 1087, 1107,\n",
       "                      1088, 1108, 1089, 1109, 1090, 1110, 1091, 1111, 1092,\n",
       "                      1112, 1093, 1113, 1094, 1114, 1095, 1115, 1096, 1116,\n",
       "                      1097, 1117, 1098, 1118, 1099, 1119, 1100, 1120, 1101,\n",
       "                      1121, 1102, 1122, 1103, 1123, 1104, 1124, 1105, 1125,\n",
       "                      1106, 1126, 1107, 1127, 1108, 1128, 1109, 1129, 1110,\n",
       "                      1130, 1111, 1131, 1112, 1132, 1113, 1133, 1114, 1134,\n",
       "                      1115, 1135, 1116, 1136, 1117, 1137, 1118, 1138, 1119,\n",
       "                      1139, 1120, 1140, 1121, 1141, 1122, 1142, 1123, 1143,\n",
       "                      1124, 1144, 1125, 1145, 1126, 1146, 1127, 1147, 1128,\n",
       "                      1148, 1129, 1149, 1130, 1150, 1131, 1151, 1132, 1152,\n",
       "                      1133, 1153, 1134, 1154, 1135, 1155, 1136, 1156, 1137,\n",
       "                      1157, 1138, 1158, 1139, 1159, 1140, 1160, 1141, 1161,\n",
       "                      1142, 1162, 1143, 1163, 1144, 1164, 1145, 1165, 1146,\n",
       "                      1166, 1147, 1167, 1148, 1168, 1149, 1169, 1150, 1170,\n",
       "                      1151, 1171, 1152, 1172, 1153, 1173, 1154, 1174, 1155,\n",
       "                      1175, 1156, 1176, 1157, 1177, 1158, 1178, 1159, 1179,\n",
       "                      1160, 1180, 1161, 1181, 1162, 1182, 1163, 1183, 1164,\n",
       "                      1184, 1165, 1185, 1166, 1186, 1167, 1187, 1168, 1188,\n",
       "                      1169, 1189, 1170, 1190, 1171, 1191, 1172, 1192, 1173,\n",
       "                      1193, 1174, 1194, 1175, 1195, 1176, 1196, 1177, 1197,\n",
       "                      1178, 1198, 1179, 1199, 1180, 1200, 1181, 1201, 1182,\n",
       "                      1202, 1183, 1203, 1184, 1204, 1185, 1205, 1186, 1206,\n",
       "                      1187, 1207, 1188, 1208, 1189, 1209, 1190, 1210, 1191,\n",
       "                      1211, 1192, 1212, 1193, 1213, 1194, 1214, 1195, 1215,\n",
       "                      1196, 1216, 1197, 1217, 1198, 1218, 1199, 1219, 1200,\n",
       "                      1220, 1201, 1221, 1202, 1222, 1203, 1223, 1204, 1224,\n",
       "                      1205, 1225, 1206, 1226, 1207, 1227, 1208, 1228, 1209,\n",
       "                      1229, 1210, 1230, 1211, 1231, 1212, 1232, 1213, 1233,\n",
       "                      1214, 1234, 1215, 1235, 1216, 1236, 1217, 1237, 1218,\n",
       "                      1238, 1219, 1239, 1220, 1240, 1221, 1241, 1222, 1242,\n",
       "                      1223, 1243, 1224, 1244, 1225, 1245, 1226, 1246, 1227,\n",
       "                      1247, 1228, 1248, 1229, 1249, 1230, 1250, 1231, 1251,\n",
       "                      1232, 1252, 1233, 1253, 1234, 1254, 1235, 1255, 1236,\n",
       "                      1256, 1237, 1257, 1238, 1258, 1239, 1259, 1240, 1260,\n",
       "                      1241, 1261, 1242, 1262, 1243, 1263, 1244, 1264, 1245,\n",
       "                      1265, 1246, 1266, 1247, 1267, 1248, 1268, 1249, 1269,\n",
       "                      1250, 1270, 1251, 1271, 1252, 1272, 1253, 1273, 1254,\n",
       "                      1274, 1255, 1275, 1256, 1276, 1257, 1277, 1258, 1278,\n",
       "                      1259, 1279, 1260, 1280, 1261, 1281, 1262, 1282, 1263,\n",
       "                      1283, 1264, 1284, 1265, 1285, 1266, 1286, 1267, 1287,\n",
       "                      1268, 1288, 1269, 1289, 1270, 1290, 1271, 1291, 1272,\n",
       "                      1292, 1273, 1293, 1274, 1294, 1275, 1295, 1276, 1296,\n",
       "                      1277, 1297, 1278, 1298, 1279, 1299, 1280, 1300, 1281,\n",
       "                      1301, 1282, 1302, 1283, 1303, 1284, 1304, 1285, 1305,\n",
       "                      1286, 1306, 1287, 1307, 1288, 1308, 1289, 1309, 1290,\n",
       "                      1310, 1291, 1311, 1292, 1312, 1293, 1313, 1294, 1314,\n",
       "                      1295, 1315, 1296, 1316, 1297, 1317, 1298, 1318, 1299,\n",
       "                      1319, 1300, 1320, 1301, 1321, 1302, 1322, 1303, 1323,\n",
       "                      1304, 1324, 1305, 1325, 1306, 1326, 1307, 1327, 1308,\n",
       "                      1328, 1309, 1329, 1310, 1330, 1311, 1331, 1312, 1332,\n",
       "                      1313, 1333, 1314, 1334, 1315, 1335, 1316, 1336, 1317,\n",
       "                      1337, 1318, 1338, 1319, 1339, 1320, 1340, 1321, 1341,\n",
       "                      1322, 1342, 1323, 1343, 1324, 1344, 1325, 1345, 1326,\n",
       "                      1346, 1327, 1347, 1328, 1348, 1329, 1349, 1330, 1350,\n",
       "                      1331, 1351, 1332, 1352, 1333, 1353, 1334, 1354, 1335,\n",
       "                      1355, 1336, 1356, 1337, 1357, 1338, 1358, 1339, 1359,\n",
       "                      1340, 1360, 1341, 1361, 1342, 1362, 1343, 1363, 1344,\n",
       "                      1364, 1345, 1365, 1346, 1366, 1347, 1367, 1348, 1368,\n",
       "                      1349, 1369, 1350, 1370, 1351, 1371, 1352, 1372, 1353,\n",
       "                      1373, 1354, 1374, 1355, 1375, 1356, 1376, 1357, 1377,\n",
       "                      1358, 1378, 1359, 1379, 1360, 1380, 1361, 1381, 1362,\n",
       "                      1382, 1363, 1383, 1364, 1384, 1365, 1385, 1366, 1386,\n",
       "                      1367, 1387, 1368, 1388, 1369, 1389, 1370, 1390, 1371,\n",
       "                      1391, 1372, 1392, 1373, 1393, 1374, 1394, 1375, 1395,\n",
       "                      1376, 1396, 1377, 1397, 1378, 1398, 1379, 1399, 1380,\n",
       "                      1400, 1381, 1401, 1382, 1402, 1383, 1403, 1384, 1404,\n",
       "                      1385, 1405, 1386, 1406, 1387, 1407, 1388, 1408, 1389,\n",
       "                      1409, 1390, 1410, 1391, 1411, 1392, 1412, 1393, 1413,\n",
       "                      1394, 1414, 1395, 1415, 1396, 1416, 1397, 1417, 1398,\n",
       "                      1418, 1399, 1419, 1400, 1420, 1401, 1421, 1402, 1422,\n",
       "                      1403, 1423, 1404, 1424, 1405, 1425, 1406, 1426, 1407,\n",
       "                      1427, 1408, 1428, 1409, 1429, 1410, 1430, 1411, 1431,\n",
       "                      1412, 1432, 1413, 1433, 1414, 1434, 1415, 1435, 1416,\n",
       "                      1436, 1417, 1437, 1418, 1438, 1419, 1439, 1420, 1440,\n",
       "                      1421, 1441, 1422, 1442, 1423, 1443, 1424, 1444, 1425,\n",
       "                      1445, 1426, 1446, 1427, 1447, 1428, 1448, 1429, 1449,\n",
       "                      1430, 1450, 1431, 1451, 1432, 1452, 1433, 1453, 1434,\n",
       "                      1454, 1435, 1455, 1436, 1456, 1437, 1457, 1438, 1458,\n",
       "                      1439, 1459, 1440, 1460, 1441, 1461, 1442, 1462, 1443,\n",
       "                      1463, 1444, 1464, 1445, 1465, 1446, 1466, 1447, 1467,\n",
       "                      1448, 1468, 1449, 1469, 1450, 1470, 1451, 1471, 1452,\n",
       "                      1472, 1453, 1473, 1454, 1474, 1455, 1475, 1456, 1476,\n",
       "                      1457, 1477, 1458, 1478, 1459, 1479, 1460, 1480, 1461,\n",
       "                      1481, 1462, 1482, 1463, 1483, 1464, 1484, 1465, 1485,\n",
       "                      1466, 1486, 1467, 1487, 1468, 1488, 1469, 1489, 1470,\n",
       "                      1490, 1471, 1491, 1472, 1492, 1473, 1493, 1474, 1494,\n",
       "                      1475, 1495, 1476, 1496, 1477, 1497, 1478, 1498, 1479,\n",
       "                      1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488,\n",
       "                      1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497,\n",
       "                      1498]),\n",
       "       size=(35000, 35000), nnz=1000, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\")\n",
    "\n",
    "# # LS = torch.zeros(n_dis, n_max, len(etypes), device=self.device) ## [N, N, E]\n",
    "# src = torch.arange(500)\n",
    "# dst = torch.arange(20, 520)\n",
    "# values = torch.arange(999, 1499)\n",
    "# # print(src)\n",
    "# ex = torch.sparse_coo_tensor(torch.stack([src, dst]), values, (35000, 35000))\n",
    "# ex2 = torch.sparse_coo_tensor(torch.stack([dst, src]), values, (35000, 35000))\n",
    "# ex + ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 10.75 GiB of which 236.50 MiB is free. Process 142512 has 10.52 GiB memory in use. Of the allocated memory 8.46 GiB is allocated by PyTorch, and 641.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20526/2920338822.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLS_nonzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLS\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# LSP_prob = torch.clamp(torch.sigmoid(LS_nonzero), min=1e-9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# LSP_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# LSP_prob = [k:torch.clamp(torch.sigmoid(v), min=1e-9) for k,v in enumerate(LS)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# LSP_norm_prob = {k: v/v.sum() for k,v in LSP_prob.items()}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 10.75 GiB of which 236.50 MiB is free. Process 142512 has 10.52 GiB memory in use. Of the allocated memory 8.46 GiB is allocated by PyTorch, and 641.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# LS_nonzero = torch.where(LS == 0, torch.tensor(float(\"-inf\")), LS)\n",
    "# LSP_prob = torch.clamp(torch.sigmoid(LS_nonzero), min=1e-9)\n",
    "# LSP_prob\n",
    "# LSP_prob = [k:torch.clamp(torch.sigmoid(v), min=1e-9) for k,v in enumerate(LS)]\n",
    "# LSP_norm_prob = {k: v/v.sum() for k,v in LSP_prob.items()}\n",
    "# LSP_norm_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('LSP.pkl', \"rb\") as file:\n",
    "#     LS_dict = pickle.load(file)\n",
    "# LS_dict\n",
    "# with open(\"LSP_allddetype.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(LSP_norm_prob, file)\n",
    "# with open(\"LSP_partialetype.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(LSP_norm_prob, file)\n",
    "\n",
    "torch.save(LS_prob, \"LSP_full_cosine.pt\")\n",
    "\n",
    "# torch.save(LS_prob, \"LSP_partial_cosine.pt\")\n",
    "# loaded = torch.load(\"LSP_partial_cosine.pt\")\n",
    "# loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/complex_disease_1/\"\n",
    "# df_train = pd.read_csv(f\"{data_path}train.csv\")\n",
    "# df_valid = pd.read_csv(f\"{data_path}valid.csv\")\n",
    "# df_test = pd.read_csv(f\"{data_path}test.csv\")\n",
    "\n",
    "# df_valid_nocheating = df_valid[(df_valid.relation != \"indication\") & (df_valid.relation != \"contraindication\")]\n",
    "df_test_nocheating = df_test[(df_test.relation != \"indication\") & (df_test.relation != \"contraindication\")]\n",
    "\n",
    "# df_valid_nocheating\n",
    "kg_no_cheating = pd.concat([df_train, df_valid_nocheating, df_test_nocheating])\n",
    "kg_no_cheating.to_csv(f\"{data_path}/kg_nocheating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problems\n",
    "# 1. Does disease pooling mechanism happen during tarining phase too? \n",
    "    # Yes. So let's enable dpm during pseudo training with only diseases in training set. \n",
    "# 2. How can I store the LS matrix with augmented disease embeddings? \n",
    "    # I did this, and pretty sure the scores were matched. But for some reason, validation phase still takes a very long time... why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = f'{saving_path}seed_1_normal'\n",
    "# TxGNN1.load_pretrained(save_dir, legacy=True)\n",
    "# G = TxGNN1.G.to(TxGNN1.device)\n",
    "# best_G = TxGNN1.best_G.to(TxGNN1.device)\n",
    "# best_model = TxGNN1.best_model.to(TxGNN1.device)\n",
    "# best_model.eval()\n",
    "# # print(TxGNN1.dd_etypes.device)\n",
    "# # TxGNN1.model = TxGNN1.model.to(TxGNN1.device)\n",
    "# # TxGNN1.best_model = TxGNN1.best_model.to(TxGNN1.device)\n",
    "# # print(TxGNN1.model)\n",
    "# # print(\"encore\")\n",
    "\n",
    "# ## Print out accuracies\n",
    "# neg_sampler = Full_Graph_NegSampler(TxGNN1.G, 1, 'fix_dst', TxGNN1.device)\n",
    "# g_train_neg = neg_sampler(TxGNN1.G)\n",
    "# g_valid_pos, g_valid_neg = TxGNN1.g_valid_pos, TxGNN1.g_valid_neg\n",
    "# g_test_pos, g_test_neg = TxGNN1.g_test_pos, TxGNN1.g_test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_pretrained(self, path, legacy=False):\n",
    "#     with open(os.path.join(path, 'config.pkl'), 'rb') as f:\n",
    "#         config = pickle.load(f)\n",
    "        \n",
    "#     self.model_initialize(**config, debug=True)\n",
    "#     self.config = config\n",
    "#     # self.G = initialize_node_embedding(self.G.to(torch.device(\"cpu\")), config['n_inp']).to(self.device)\n",
    "    \n",
    "#     state_dict = torch.load(os.path.join(path, 'model.pt'), map_location = torch.device('cpu'))\n",
    "#     if legacy: \n",
    "#         state_dict_G = torch.load(os.path.join(path, 'G.pt'), map_location = torch.device('cpu'))\n",
    "#     else:\n",
    "#         state_dict_G = torch.load(os.path.join(path, 'best_G.pt'), map_location = torch.device('cpu'))\n",
    "#         # if next(iter(state_dict))[:7] == 'module.':\n",
    "#         #     # the pretrained model is from data-parallel module\n",
    "#         #     from collections import OrderedDict\n",
    "#         #     new_state_dict = OrderedDict()\n",
    "#         #     for k, v in state_dict.items():\n",
    "#         #         name = k[7:] # remove `module.`\n",
    "#         #         new_state_dict[name] = v\n",
    "#         #     state_dict = new_state_dict\n",
    "#         self.g_valid_pos = torch.load(os.path.join(path, 'g_valid_pos.pt'))\n",
    "#         self.g_valid_neg = torch.load(os.path.join(path, 'g_valid_neg.pt'))\n",
    "#         self.g_test_pos = torch.load(os.path.join(path, 'g_test_pos.pt'))\n",
    "#         self.g_test_neg = torch.load(os.path.join(path, 'g_test_neg.pt'))\n",
    "#     self.model.load_state_dict(state_dict)\n",
    "#     for ntype, embs in state_dict_G.items():\n",
    "#         self.G.nodes[ntype].data['inp'] = embs\n",
    "#         if not legacy:\n",
    "#             self.best_G.nodes[ntype].data['inp'] = embs\n",
    "\n",
    "#     self.model = self.model.to(self.device)\n",
    "#     self.G = self.G.to(self.device)\n",
    "#     self.best_G = self.best_G.to(self.device)\n",
    "#     self.best_model = self.model\n",
    "#     print(f\"Checkpoint loaded from path: {path}\")\n",
    "\n",
    "# load_pretrained(TxGNN1, save_dir, legacy=True)\n",
    "# G = TxGNN1.G.to(TxGNN1.device)\n",
    "# # best_G = TxGNN1.best_G.to(TxGNN1.device)\n",
    "# best_model = TxGNN1.best_model.to(TxGNN1.device)\n",
    "# best_model.eval()\n",
    "# # print(TxGNN1.dd_etypes.device)\n",
    "# # TxGNN1.model = TxGNN1.model.to(TxGNN1.device)\n",
    "# # TxGNN1.best_model = TxGNN1.best_model.to(TxGNN1.device)\n",
    "# # print(TxGNN1.model)\n",
    "# # print(\"encore\")\n",
    "\n",
    "# ## Print out accuracies\n",
    "# neg_sampler = Full_Graph_NegSampler(TxGNN1.G, 1, 'fix_dst', TxGNN1.device)\n",
    "# g_train_neg = neg_sampler(TxGNN1.G)\n",
    "# g_valid_pos, g_valid_neg = TxGNN1.g_valid_pos, TxGNN1.g_valid_neg\n",
    "# g_test_pos, g_test_neg = TxGNN1.g_test_pos, TxGNN1.g_test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_disease['disease_query_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = torch.isin(h_disease['disease_query_id'][0], h_disease['disease_key_id'][0])\n",
    "# seen = mask.nonzero().squeeze() ## what does squeeze() do here? \n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_values, topk_indices = torch.topk(sim[seen], self.k + 1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = torch.zeros(h_disease['disease_query'].shape)\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.isin(h_disease['disease_query_id'][0], h_disease['disease_key_id'][0])\n",
    "k=3\n",
    "\n",
    "## any eval_g is in Train_G\n",
    "coef = torch.zeros(sim.size(0), k, device=torch.device(\"cuda\"))\n",
    "embed = torch.zeros(h_disease['disease_query'].shape, device=torch.device(\"cuda\"))\n",
    "# seen_any = mask.nonzero().squeeze() > 0\n",
    "seen = mask.nonzero().squeeze() ## what does squeeze() do here? \n",
    "sim = sim.to(torch.device(\"cuda\"))\n",
    "if len(seen) > 0:\n",
    "    topk_values, topk_indices = torch.topk(sim[seen], k + 1, dim=1)\n",
    "    coef[seen] = F.normalize(topk_values[:, 1:], p=1, dim=1)\n",
    "    embed[seen] = h_disease['disease_key'][topk_indices[:, 1:]]\n",
    "\n",
    "unseen = (~mask).nonzero().squeeze()\n",
    "if len(unseen) > 0:\n",
    "    topk_values, topk_indices = torch.topk(sim[unseen], k, dim=1)\n",
    "    coef[unseen] = F.normalize(topk_values, p=1, dim=1)\n",
    "    embed[unseen] = h_disease['disease_key'][topk_indices]\n",
    "out = torch.mul(embed, coef.unsqueeze(dim = 2).to(torch.device(\"cuda\"))).sum(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv\n",
    "import pickle\n",
    "with open(\"pseudo_valid_restrained_saveG.pkl\", 'rb') as file:\n",
    "    test = pickle.load(file)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score_pos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(951.0067, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "1039\n"
     ]
    }
   ],
   "source": [
    "print(pred_score_pos[('drug', 'indication', 'disease')].sum())\n",
    "print(len(pred_score_pos[('drug', 'indication', 'disease')]))\n",
    "# print(pred_score_pos[('drug', 'contraindication', 'disease')].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_idx</th>\n",
       "      <th>y_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475906</th>\n",
       "      <td>885.0</td>\n",
       "      <td>12661.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475908</th>\n",
       "      <td>301.0</td>\n",
       "      <td>12661.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475909</th>\n",
       "      <td>7534.0</td>\n",
       "      <td>12661.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475910</th>\n",
       "      <td>804.0</td>\n",
       "      <td>12661.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475911</th>\n",
       "      <td>742.0</td>\n",
       "      <td>12661.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480565</th>\n",
       "      <td>385.0</td>\n",
       "      <td>14500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480566</th>\n",
       "      <td>693.0</td>\n",
       "      <td>14500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480567</th>\n",
       "      <td>5786.0</td>\n",
       "      <td>15175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480568</th>\n",
       "      <td>187.0</td>\n",
       "      <td>13194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480569</th>\n",
       "      <td>1178.0</td>\n",
       "      <td>1484.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4306 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_idx    y_idx\n",
       "475906   885.0  12661.0\n",
       "475908   301.0  12661.0\n",
       "475909  7534.0  12661.0\n",
       "475910   804.0  12661.0\n",
       "475911   742.0  12661.0\n",
       "...        ...      ...\n",
       "480565   385.0  14500.0\n",
       "480566   693.0  14500.0\n",
       "480567  5786.0  15175.0\n",
       "480568   187.0  13194.0\n",
       "480569  1178.0   1484.0\n",
       "\n",
       "[4306 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_df_valid[[\"x_idx\", \"y_idx\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/home/euku/teams/b12/TxGNN/pseudo_valid_restrained_saveG.pkl'\n",
    "with open(fname, \"rb\") as file:\n",
    "    pseudo_valid = pickle.load(file)\n",
    "\n",
    "# data_path = \"./data/complex_disease_1/\"\n",
    "# df_valid = pd.read_csv(f\"{data_path}valid.csv\")\n",
    "# dd_df_valid = df_valid[(df_valid.relation == \"indication\")]\n",
    "# dd_df_valid\n",
    "\n",
    "# rows = []\n",
    "# for k, v in pseudo_valid[\"ranked_scores\"].items():\n",
    "#     for i, score in enumerate(v):\n",
    "#         rows.append({'y_idx': k, 'score': score, 'x_idx': i})\n",
    "# df_pseud_valid = pd.DataFrame(rows)\n",
    "# df_pseud_valid\n",
    "\n",
    "# df_pseud_valid['x_idx'] = df_pseud_valid['x_idx'].astype(float)\n",
    "# df_pseud_valid['y_idx'] = df_pseud_valid['y_idx'].astype(float)\n",
    "\n",
    "# temp = df_pseud_valid.merge(dd_df_valid[[\"x_idx\", \"y_idx\"]], on=[\"x_idx\", 'y_idx'], how='inner')\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using stored similarity matrix for ('drug', 'contraindication', 'disease')\n",
      "Using stored similarity matrix for ('drug', 'indication', 'disease')\n",
      "tensor(1102.1118, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## How to extract the relation\n",
    "with torch.no_grad():\n",
    "    ## obtain the distmult, add an argument so I obtain the corresponding edge relation as well. \n",
    "    # h, beta_kl_loss, distmult = best_model(best_G, g_train_neg, pretrain_mode = False, mode = 'train', return_h_and_kl=True)\n",
    "    h, beta_kl_loss, distmult = best_model(best_G, pretrain_mode = False, mode = 'train', return_h_and_kl=True)\n",
    "    ## distmult params: (eval_G, G, h, pretrain_mode, mode = mode + '_pos', pseudo_training=pseudo_training)\n",
    "    pred_score_pos, out_pos = distmult(g_valid_pos, best_G, h, pretrain_mode=False, mode='train_pos')\n",
    "    # pred_score_neg, out_neg = distmult(g_valid_neg, best_G, h, pretrain_mode=False, mode='train_pos')\n",
    "    # print(out_pos.sum())\n",
    "    print(pred_score_pos[('drug', 'indication', 'disease')].sum())\n",
    "\n",
    "    # pseudo_dd_etypes = [('drug', 'contraindication', 'disease'), \n",
    "    #                     ('drug', 'indication', 'disease'), ]\n",
    "    # srcdst_dict = {f\"{k}_pos\": [] for k in pseudo_dd_etypes}\n",
    "    # srcdst_dict.update({f\"{k}_neg\": [] for k in pseudo_dd_etypes})\n",
    "    # for k in pseudo_dd_etypes:\n",
    "    #     srcdst_dict[f\"{k}_pos\"] = pred_score_pos[f\"{k}_srcdst\"]\n",
    "    #     srcdst_dict[f\"{k}_neg\"] = pred_score_pos[f\"{k}_srcdst\"]\n",
    "    #     print(srcdst_dict[f\"{k}_neg\"])\n",
    "    #     break\n",
    "\n",
    "    # pred_score_pos, pred_score_neg, pos_score, neg_score, _ = model(G, g_neg, g_pos, pretrain_mode = False, mode = 'mode')\n",
    "    \n",
    "#     pos_score = torch.cat([pred_score_pos[i] for i in dd_etypes])\n",
    "#     neg_score = torch.cat([pred_score_neg[i] for i in dd_etypes])\n",
    "    \n",
    "#     scores = torch.sigmoid(torch.cat((pos_score, neg_score)).reshape(-1,))\n",
    "#     # labels = [1] * len(pos_score) + [0] * len(neg_score)\n",
    "#     labels = torch.cat((torch.ones(len(pos_score), device=device),\n",
    "#                         torch.zeros(len(neg_score), device=device)))\n",
    "#     loss = F.binary_cross_entropy(scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0412,  0.0533,  0.0185,  ...,  0.0007, -0.0095,  0.0091],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_score_pos[('drug', 'indication', 'disease')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_idx</th>\n",
       "      <th>score</th>\n",
       "      <th>x_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [y_idx, score, x_idx]\n",
       "Index: []"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortened_pseudo_valid[shortened_pseudo_valid.y_idx == 15175.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_type</th>\n",
       "      <th>x_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>y_type</th>\n",
       "      <th>y_id</th>\n",
       "      <th>x_idx</th>\n",
       "      <th>y_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [x_type, x_id, relation, y_type, y_id, x_idx, y_idx]\n",
       "Index: []"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pseudo_valid[\"ranked_scores\"].keys()\n",
    "dis_valid_ind[dis_valid_ind.y_idx == 15665.0]\n",
    "# dis_valid_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19       7875.0\n",
      "21      15045.0\n",
      "26      12661.0\n",
      "33      13149.0\n",
      "40       5941.0\n",
      "         ...   \n",
      "5171      367.0\n",
      "5173    14285.0\n",
      "5174    12735.0\n",
      "5175    14559.0\n",
      "5176    15409.0\n",
      "Length: 168, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y_idx    1.005916e+07\n",
       "score    1.420248e+03\n",
       "x_idx    2.293077e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = '/home/euku/teams/b12/TxGNN/pseudo_valid_restrained_saveG.pkl'\n",
    "with open(fname, \"rb\") as file:\n",
    "    pseudo_valid = pickle.load(file)\n",
    "\n",
    "df_valid = TxGNN1.df_valid\n",
    "# dis_idxs = [v for k,v in pseudo_valid['dis_idx'].items()]\n",
    "dis_valid_ind = df_valid[df_valid.relation == \"indication\"]\n",
    "dis_valid_idxs = df_valid[df_valid.relation == \"indication\"].y_idx\n",
    "dis_idxs = [pseudo_valid['dis_idx'][k] for k in pseudo_valid[\"ranked_scores\"].keys()]\n",
    "mask = pd.Series(dis_idxs).isin(dis_valid_idxs)\n",
    "\n",
    "# print(mask.sum())\n",
    "print(pd.Series(dis_idxs)[mask])\n",
    "\n",
    "rows = []\n",
    "for i, (b, (k, dis_scores)) in enumerate(zip(mask.values, pseudo_valid[\"ranked_scores\"].items())):\n",
    "    if b:\n",
    "        for drug_i, score in enumerate(dis_scores):\n",
    "            rows.append({'y_idx': dis_idxs[i], 'score': score, 'x_idx': drug_i})\n",
    "\n",
    "shortened_pseudo_valid = pd.DataFrame(rows)\n",
    "shortened_pseudo_valid['y_idx'] = shortened_pseudo_valid['y_idx'].astype(\"float\")\n",
    "shortened_pseudo_valid['x_idx'] = shortened_pseudo_valid['x_idx'].astype(\"float\")\n",
    "shortened_pseudo_valid\n",
    "\n",
    "shortened_pseudo_valid.merge(dis_valid_ind[[\"x_idx\", \"y_idx\"]], on=['y_idx'], how=\"inner\")\n",
    "len(shortened_pseudo_valid.merge(dis_valid_ind[[\"x_idx\", \"y_idx\"]], on=['y_idx'], how=\"inner\").y_idx.unique())\n",
    "\n",
    "shortened_pseudo_valid.merge(dis_valid_ind[[\"x_idx\", \"y_idx\"]], on=['x_idx', 'y_idx'], how=\"inner\").score.sum()\n",
    "\n",
    "# sum([float(x) for x in pseudo_valid[\"ranked_scores\"].keys()])\n",
    "# sum([float(x) for x in pseudo_valid[\"ranked_scores\"].keys()])\n",
    "# [x for x in pseudo_valid[\"ranked_scores\"].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1420.2483"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortened_pseudo_valid.merge(dis_valid_ind[[\"x_idx\", \"y_idx\"]], on=['x_idx', 'y_idx'], how=\"inner\").score.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
